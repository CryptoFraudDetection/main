---
jupyter: python3
---

```{python}
from pathlib import Path
import os

import numpy as np
import pandas as pd
import torch
import torchmetrics
import tqdm
from torch import nn, optim
from torch.nn.utils import rnn
from torch.utils.data import DataLoader
from torchmetrics import classification

import wandb
from CryptoFraudDetection.utils import data_pipeline, enums, logger

from sktime.transformations.panel.rocket import MultiRocketMultivariate
from sklearn.linear_model import RidgeClassifierCV

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import RidgeClassifierCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import make_pipeline
```

```{python}

torch.manual_seed(42)
np.random.seed(42)

_LOGGER = logger.Logger(
    name=__name__,
    level=enums.LoggerMode.INFO,
    log_dir="../logs",
)
```

```{python}
notebook_dir = Path(os.getcwd())
data_path = notebook_dir.parent / "data" 

if not data_path.exists():
    raise FileNotFoundError(f"Data directory not found: {data_path}")
print(f"Data directory found: {data_path}")
```

```{python}
crypto_data = data_pipeline.CryptoData(_LOGGER, data_dir=data_path)
train_df, _ = crypto_data.load_data()
train_coins = train_df["coin"].unique()
labels = train_df["fraud"]

dataset_config = {
    "n_cutoff_points": 1,
    "n_groups_cutoff_points": 1,
    }
```

```{python}
train_coins
```

```{python}
train_dataset = data_pipeline.CryptoDataSet(
    df=train_df,
    logger_=_LOGGER,
    **dataset_config,
)
```

```{python}
num_samples = len(train_dataset)
print(f"Number of samples in the dataset: {num_samples}")

sample_index = 0
x, y = train_dataset[sample_index]

print(f"Shape of features (x): {x.shape}")
print(f"Value of target (y): {y}")
```

```{python}
def prepare_data_for_multirocket(dataset):

    X = []
    y = []

    for i in range(len(dataset)):
        x, label = dataset[i]

        x_transformed = pd.DataFrame(x.numpy()).T
        X.append(x_transformed)
        y.append(label.item())

    X = pd.concat(X, axis=0, ignore_index=True)
    y = pd.Series(y)

    return X, y

X_no_cuts, y_no_cuts = prepare_data_for_multirocket(train_dataset)

print(f"Shape of X: {X_no_cuts.shape}")
print(f"Shape of y: {y.shape}")
print(f"First 5 y values: {y_no_cuts.head()}")
```

```{python}
y_no_cuts
```

```{python}
X_no_cuts
```

```{python}
'''    

def generate_random_time_windows(max_days, n_windows, random_state=None):
    """
    Generiert zufällige Zeitfenster mit definiertem Anfang (1) und Ende (max_days),
    wobei näher an 1 mehr Zeitfenster generiert werden und weiter entfernt weniger.
    
    Args:
        max_days (int): Maximale Anzahl der Tage (z. B. 730 für 2 Jahre).
        n_windows (int): Anzahl der zu generierenden Zeitfenster.
        random_state (int, optional): Seed für Reproduzierbarkeit.
    
    Returns:
        list: Zufällig generierte Zeitfenster in Tagen.
    """
    rng = np.random.default_rng(random_state)
    
    # Generiere eine umgekehrte lineare Verteilungsgewichtung
    possible_days = np.arange(2, max_days + 1)  # Tage ab 2 bis max_days (inklusive)
    weights = np.linspace(0, 1, len(possible_days))  # Gewichtung für mögliche Tage (steigend)
    
    # Normalisiere die Gewichtung
    weights /= weights.sum()
    
    # Ziehe zufällige Tage basierend auf den Gewichten
    random_days = rng.choice(
        possible_days,
        size=n_windows - 2,  # Anzahl der Tage abzüglich Start und Ende
        replace=False,
        p=weights
    )
    
    # Füge Start (1) und Ende (max_days) hinzu und sortiere
    time_windows = [1] + sorted(random_days) + [max_days]
    
    return time_windows





def prepare_multivariate_time_series(data, n_coins, n_features, time_windows, max_length, labels):
    """
    Bereitet multivariate Zeitfensterdaten mit konsistentem Links-Padding vor.
    
    Args:
        data (pd.DataFrame): Originaldaten mit 9333 Zeilen (9 Coins x 1037 Features).
        n_coins (int): Anzahl der Coins (z. B. 9).
        n_features (int): Anzahl der Zeitreihen pro Coin (z. B. 1037).
        time_windows (list): Liste der Zeitfenster in Werten (z. B. [180, 360, 900, 2160]).
        max_length (int): Maximale Länge der gepaddeten Zeitreihe.
        labels (np.ndarray): Array mit Labels (0 oder 1) für jeden Coin.
        
    Returns:
        np.ndarray: MultiRocket-kompatible Daten im Format (n_samples, n_features, n_timepoints).
        np.ndarray: Labels für die Klassifikation (z. B. Betrug ja/nein).
    """
    all_samples = []
    final_labels = []

    for coin_idx in range(n_coins):
        start_idx = coin_idx * n_features
        end_idx = (coin_idx + 1) * n_features
        coin_data = data.iloc[start_idx:end_idx]

        for time_window in time_windows:
            time_series = []

            for _, row in coin_data.iterrows():
                valid_values = row.dropna().values

                if len(valid_values) >= time_window:
                    window_values = valid_values[:time_window]
                else:
                    window_values = np.pad(
                        valid_values,
                        (time_window - len(valid_values), 0),
                        constant_values=np.nan
                    )

                # Links-Padding für Standardisierung der Länge
                padded_values = np.pad(
                    window_values,
                    (max_length - len(window_values), 0),
                    constant_values=np.nan
                )
                time_series.append(padded_values)

            all_samples.append(np.array(time_series))

            final_labels.append(labels[coin_idx])

    all_samples = np.array(all_samples)
    assert all_samples.shape[1:] == (n_features, max_length), "Uneinheitliche Shapes der Zeitreihen!"
    return all_samples, np.array(final_labels)
'''
```

```{python}
def generate_random_time_windows(max_days, n_windows, random_state=None):
    """
    Generiert zufällige Zeitfenster mit definiertem Anfang (1) und Ende (max_days),
    wobei näher an 1 mehr Zeitfenster generiert werden und weiter entfernt weniger.
    
    Args:
        max_days (int): Maximale Anzahl der Tage (z. B. 730 für 2 Jahre).
        n_windows (int): Anzahl der zu generierenden Zeitfenster.
        random_state (int, optional): Seed für Reproduzierbarkeit.
    
    Returns:
        list: Zufällig generierte Zeitfenster in Tagen.
    """
    rng = np.random.default_rng(random_state)
    
    possible_days = np.arange(2, max_days + 1)
    weights = np.linspace(1, 0, len(possible_days))
    
    weights /= weights.sum()
    
    random_days = rng.choice(
        possible_days,
        size=n_windows - 2,
        replace=False,
        p=weights
    )
    
    time_windows = [1] + sorted(random_days) + [max_days]
    
    return time_windows
def prepare_multivariate_time_series(data, n_coins, n_features, time_windows, max_length, labels, start_days=None):
    """
    Bereitet multivariate Zeitfensterdaten mit konsistentem Links-Padding vor.

    Args:
        data (pd.DataFrame): Originaldaten mit 9333 Zeilen (9 Coins x 1037 Features).
        n_coins (int): Anzahl der Coins (z. B. 9).
        n_features (int): Anzahl der Zeitreihen pro Coin (z. B. 1037).
        time_windows (list): Liste der Zeitfenster in Werten (z. B. [180, 360, 900, 2160]).
        max_length (int): Maximale Länge der gepaddeten Zeitreihe.
        labels (np.ndarray): Array mit Labels (0 oder 1) für jeden Coin.
        start_days (list, optional): Liste der möglichen Startpunkte in Tagen.

    Returns:
        np.ndarray: MultiRocket-kompatible Daten im Format (n_samples, n_features, n_timepoints).
        np.ndarray: Labels für die Klassifikation (z. B. Betrug ja/nein).
    """
    all_samples = []
    final_labels = []

    if start_days is None:
        start_days = [0]

    for coin_idx in range(n_coins):
        start_idx = coin_idx * n_features
        end_idx = (coin_idx + 1) * n_features
        coin_data = data.iloc[start_idx:end_idx]

        for start_day in start_days:
            for time_window in time_windows:
                time_series = []

                for _, row in coin_data.iterrows():
                    valid_values = row.dropna().values

                    if len(valid_values) > start_day:
                        valid_values = valid_values[start_day:]
                    else:
                        valid_values = []

                    if len(valid_values) >= time_window:
                        window_values = valid_values[:time_window]  # Von links nach rechts
                    else:
                        window_values = np.pad(
                            valid_values,
                            (time_window - len(valid_values), 0),
                            constant_values=np.nan
                        )

                    padded_values = np.pad(
                        window_values,
                        (max_length - len(window_values), 0),
                        constant_values=np.nan
                    )
                    time_series.append(padded_values)

                all_samples.append(np.array(time_series))
                final_labels.append(labels[coin_idx])

    all_samples = np.array(all_samples)
    assert all_samples.shape[1:] == (n_features, max_length), "Uneinheitliche Shapes der Zeitreihen!"
    return all_samples, np.array(final_labels)

n_coins = 9
n_features = 1037

time_windows_days = generate_random_time_windows(max_days=365, n_windows=20, random_state=42)
time_windows = [window * 6 for window in time_windows_days]
start_days = [0, 5, 10]
max_length = max(time_windows)

# Transformiere die Daten
X, y = prepare_multivariate_time_series(X_no_cuts, n_coins, n_features, time_windows, max_length, y_no_cuts, start_days)
print(f"Shape of X: {X.shape}")
print(f"Shape of y: {y.shape}")
print(f"Labels: {y}")
```

```{python}
#y to 0 or 1 
y = y.astype(int)
y
```

```{python}
#fillna in x with 0
X = X.astype(np.float64)

X = np.nan_to_num(X)

print(f"X dtype: {X.dtype}, X shape: {X.shape}")
```

```{python}
y = y.astype(np.int64)  # oder np.float64
print(f"y dtype: {y.dtype}, y shape: {y.shape}")
```

```{python}
multirocket = MultiRocketMultivariate(n_jobs=-1)
count_windows = len(time_windows_days)*len(start_days)

X_test = X[:((2*count_windows)-len(X))]
y_test = y[:((2*count_windows)-len(X))]

X_train = X[((2*count_windows)-len(X)):]
y_train = y[((2*count_windows)-len(X)):]


scaler = StandardScaler()

n_samples, n_features, n_timepoints = X.shape
X_reshaped = X.reshape(n_samples, -1)

X_train_scaled = scaler.fit_transform(X_reshaped[len(X_test):])
X_test_scaled = scaler.transform(X_reshaped[:len(X_test)])

X_train_scaled = X_train_scaled.reshape(len(X_train), n_features, n_timepoints)
X_test_scaled = X_test_scaled.reshape(len(X_test), n_features, n_timepoints)

multirocket.fit(X_train_scaled, y_train)

X_transformed_train = multirocket.transform(X_train_scaled)
X_transformed_test = multirocket.transform(X_test_scaled)
print(f"Shape of transformed X_train: {X_transformed_train.shape}")
print(f"Shape of transformed X_test: {X_transformed_test.shape}")
```

```{python}
X_transformed_train
```

```{python}
y_train
```

```{python}


rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)


rf.fit(X_transformed_train, y_train)

train_predictions = rf.predict(X_transformed_train)

print("Classification Report:")
print(classification_report(y_train, train_predictions))

results_df = pd.DataFrame({
    "True_Label": y_train,
    "Prediction": train_predictions,
    "Coin": [f"Coin_{i // 4 + 1}" for i in range(len(y_train))]
})

plt.figure(figsize=(12, 6))
sns.scatterplot(
    x=range(len(y_train)),
    y=results_df["True_Label"],
    label="True Labels",
    marker="o",
    color="blue"
)
sns.scatterplot(
    x=range(len(train_predictions)),
    y=results_df["Prediction"],
    label="Predictions",
    marker="x",
    color="red"
)

plt.title("True Labels vs. Predictions")
plt.xlabel("Data Index")
plt.ylabel("Labels")
plt.legend()
plt.show()
```

```{python}
predictions_test = rf.predict(X_transformed_test)

print("Classification Report:")
print(classification_report(y_test, predictions_test))

results_df = pd.DataFrame({
    "True_Label": y_test,
    "Prediction": predictions_test,
    "Coin": [f"Coin_{i // 4 + 1}" for i in range(len(y_test))]
})

plt.figure(figsize=(12, 6))
sns.scatterplot(
    x=range(len(y_test)),
    y=results_df["True_Label"],
    label="True Labels",
    marker="o",
    color="blue"
)
sns.scatterplot(
    x=range(len(predictions_test)),
    y=results_df["Prediction"],
    label="Predictions",
    marker="x",
    color="red"
)

plt.title("True Labels vs. Predictions")
plt.xlabel("Data Index")
plt.ylabel("Labels")
plt.legend()
plt.show()
```


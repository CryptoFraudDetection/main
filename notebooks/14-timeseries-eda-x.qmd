---
jupyter: python3
---

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import json
import numpy as np
```

```{python}
df = pd.read_parquet("../data/processed/x_posts.parquet")
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.head(5)
```

```{python}
with open('../data/raw/coins.json', 'r') as f:
    coins_data = json.load(f)

coin_to_dates = {}
for coin in coins_data:
    coin_name = coin['name']
    start_date_str = coin['start_date']
    end_date_str = coin['end_date'] or '2024-11-01'
    start_date = pd.to_datetime(start_date_str)
    end_date = pd.to_datetime(end_date_str)
    coin_to_dates[coin_name] = (start_date, end_date)

keyword_to_coin = {
    'Bitcoin': 'Bitcoin',
    'Ethereum': 'Ethereum',
    'Chainlink': 'Chainlink',
    'thorchain': 'THORChain',
    '$Atom': 'Cosmos',
    'Bitforex': 'BitForex',
    '$Avax': 'Avalanche',
    'Terra Luna': 'Terra Luna',
    '$FTT': 'FTX Token',
    'Safemoon': 'Safe Moon',
    '$STA': 'STOA Network',
    'Beercoin': 'BeerCoin',
    'Teddy Doge': 'Teddy Doge'
}

df_keywords = ['Bitcoin', 'Ethereum', 'Chainlink', 'thorchain', '$Atom', 'Bitforex', '$Avax', 'Terra Luna', '$FTT', 'Safemoon', '$STA', 'Beercoin', 'Teddy Doge']
missing_keywords = set(df_keywords) - set(keyword_to_coin.keys())
if missing_keywords:
    print(f"Missing mappings for keywords: {missing_keywords}")

df['timestamp'] = pd.to_datetime(df['timestamp'])
df['date'] = df['timestamp'].dt.date
grouped = df.groupby(['searchkeyword', 'date']).size().reset_index(name='count')
grouped = grouped.sort_values('date')
keywords = df['searchkeyword'].unique()
N = len(keywords)
fig, axes = plt.subplots(N, 1, figsize=(12, N * 2), sharex=True)

for i, keyword in enumerate(keywords):
    ax = axes[i] if N > 1 else axes
    data = grouped[grouped['searchkeyword'] == keyword]
    data = data.set_index('date').reindex(
        pd.date_range(start=grouped['date'].min(), end=grouped['date'].max()), fill_value=0
    )
    data['count_smooth'] = data['count']
    ax.plot(data.index, data['count_smooth'])
    ax.set_title(keyword)
    ax.set_ylabel('Count')
    
    coin_name = keyword_to_coin.get(keyword)
    if coin_name:
        start_date, end_date = coin_to_dates.get(coin_name, (None, None))
        if start_date and end_date:
            ax.axvline(x=start_date, color='red', linestyle='--')
            ax.axvline(x=end_date, color='red', linestyle='--')
    
    if i == N - 1:
        ax.set_xlabel('Date')
    else:
        ax.set_xlabel('')
    ax.tick_params(axis='x', rotation=45)
    ax.grid(True)

plt.tight_layout()
plt.suptitle('Count of Search Keywords over Time', y=1.02)
plt.subplots_adjust(hspace=0.3)
plt.show()
```

In this plot we can see the Count of Tweets of every coin over the time. In red we can see the start and enddate which we are interested in. Some peaks in the Bitcoin Timeseries are very high because this Data is from a time where we test scraped without the Timeblock-function and we dont want to delete this data. Same happend to FTT

```{python}
#cut out coins of test data
test_coins = ['Ethereum', '$Atom', '$FTT', 'Safemoon']

df_train = df[~df['searchkeyword'].isin(test_coins)]
df_train
```

```{python}
words_list = ['moon', 'mooon', 'to 0', 'to zero', 'scam', 'fraud', 'rug', 'rugpull', 'pump', 'dump', 'rich', 'poor', 'millionaire', 'billionaire']
```

```{python}
#price data

df_btc = pd.read_csv('../data/raw/coin_price_data/btc.csv')
df_link = pd.read_csv('../data/raw/coin_price_data/link.csv')
df_avax = pd.read_csv('../data/raw/coin_price_data/avax.csv')
df_beer = pd.read_csv('../data/raw/coin_price_data/beer.csv')
df_bitforex = pd.read_csv('../data/raw/coin_price_data/bitforex.csv')
df_sta = pd.read_csv('../data/raw/coin_price_data/sta.csv')
df_rune = pd.read_csv('../data/raw/coin_price_data/rune.csv')
df_teddydoge = pd.read_csv('../data/raw/coin_price_data/teddydoge.csv')
df_luna = pd.read_csv('../data/raw/coin_price_data/luna.csv')
df_safemoon = pd.read_csv('../data/raw/coin_price_data/safemoon.csv')
df_atom = pd.read_csv('../data/raw/coin_price_data/atom.csv')
df_ftx = pd.read_csv('../data/raw/coin_price_data/ftx.csv')
df_eth = pd.read_csv('../data/raw/coin_price_data/eth.csv')

#time to datetime
df_btc['time'] = pd.to_datetime(df_btc['time'])
df_link['time'] = pd.to_datetime(df_link['time'])
df_avax['time'] = pd.to_datetime(df_avax['time'])
df_beer['time'] = pd.to_datetime(df_beer['time'])
df_bitforex['time'] = pd.to_datetime(df_bitforex['time'])
df_sta['time'] = pd.to_datetime(df_sta['time'])
df_rune['time'] = pd.to_datetime(df_rune['time'])
df_teddydoge['time'] = pd.to_datetime(df_teddydoge['time'])
df_luna['time'] = pd.to_datetime(df_luna['time'])
df_safemoon['time'] = pd.to_datetime(df_safemoon['time'])
df_atom['time'] = pd.to_datetime(df_atom['time'])
df_ftx['time'] = pd.to_datetime(df_ftx['time'])
df_eth['time'] = pd.to_datetime(df_eth['time'])
```

```{python}
# Function to generate heatmaps
def create_heatmaps(df, words_list):
    for keyword in df['searchkeyword'].unique():
        subset = df[df['searchkeyword'] == keyword]
        
        start_date = subset['timestamp'].min().date() - pd.Timedelta(days=10)
        end_date = subset['timestamp'].max().date() + pd.Timedelta(days=10)
        all_dates = pd.date_range(start_date, end_date).date
        
        heatmap_data = pd.DataFrame(0, index=words_list, columns=all_dates)
        
        for _, row in subset.iterrows():
            tweet_date = row['timestamp'].date()
            for word in words_list:
                if word in row['tweet'].lower():
                    heatmap_data.at[word, tweet_date] += 1

        for date in all_dates:
            if date not in heatmap_data.columns:
                heatmap_data[date] = 0
        
        plt.figure(figsize=(12, 6), facecolor='white')
        plt.title(f"Heatmap for Searchkeyword: {keyword}", fontsize=14)
        plt.xlabel("Date", fontsize=12)
        plt.ylabel("Words", fontsize=12)

        xticks_indices = np.linspace(0, len(all_dates) - 1, min(10, len(all_dates))).astype(int)
        xticks_labels = [all_dates[i] for i in xticks_indices]
        
        plt.xticks(xticks_indices, xticks_labels, rotation=45, fontsize=10)
        plt.yticks(range(len(words_list)), words_list, fontsize=10)
        
        plt.imshow(heatmap_data, aspect='auto', cmap='viridis', interpolation='nearest', origin='lower')
        plt.colorbar(label='Frequency', orientation='vertical')
        plt.tight_layout()
        plt.show()

create_heatmaps(df_train, words_list)
```

In these plot we can see heatmaps for every coin in the Trainset showing how much some words occured over time. It is visible, that words like moon or pump are a little bit more used in Scamcoins.

```{python}
#plot all close prices of all coins as subplots with their own x axis
fig, axes = plt.subplots(4, 3, figsize=(20, 20), sharex=True)
axes = axes.flatten()

for i, (coin_df, coin_name) in enumerate([
    (df_btc, 'Bitcoin'),
    (df_eth, 'Ethereum'),
    (df_link, 'Chainlink'),
    (df_rune, 'THORChain'),
    (df_atom, 'Cosmos'),
    (df_bitforex, 'BitForex'),
    (df_avax, 'Avalanche'),
    (df_luna, 'Terra Luna'),
    (df_ftx, 'FTX Token'),
    (df_safemoon, 'Safe Moon'),
    (df_sta, 'STOA Network'),
    (df_teddydoge, 'Teddy Doge')
]):
    ax = axes[i]
    ax.plot(coin_df['time'], coin_df['close'])
    ax.set_title(coin_name)
    ax.set_ylabel('Close Price')
    ax.set_xlabel('Date')
    ax.grid(True)
    ax.tick_params(axis='x', rotation=45)
    
plt.tight_layout()
plt.suptitle('Close Prices of Coins over Time', y=1.02)
plt.subplots_adjust(hspace=0.3)
plt.show()
```


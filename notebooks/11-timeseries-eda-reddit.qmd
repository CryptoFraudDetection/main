---
jupyter: python3
title: Scrape Reddit Posts
---
```{python}
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import json
import numpy as np
```

```{python}
df = pd.read_parquet("../data/processed/reddit_posts.parquet")
```
```{python}
df['created'] = pd.to_datetime(df['created'])
df.head(5)
```
## Import used Coins from Json and define Keyword
```{python}
with open('../data/raw/coins.json', 'r') as f:
    coins_data = json.load(f)

coin_to_dates = {}
for coin in coins_data:
    coin_name = coin['name']
    start_date_str = coin['start_date']
    end_date_str = coin['end_date'] or '2024-11-01'
    start_date = pd.to_datetime(start_date_str)
    end_date = pd.to_datetime(end_date_str)
    coin_to_dates[coin_name] = (start_date, end_date)

keyword_to_coin = {
    'Bitcoin': 'Bitcoin',
    'Ethereum': 'Ethereum',
    'Chainlink': 'Chainlink',
    'thorchain': 'THORChain',
    '$Atom': 'Cosmos',
    'Bitforex': 'BitForex',
    '$Avax': 'Avalanche',
    'Terra Luna': 'Terra Luna',
    '$FTT': 'FTX Token',
    'Safemoon': 'Safe Moon',
    '$STA': 'STOA Network',
    'Beercoin': 'BeerCoin',
    'Teddy Doge': 'Teddy Doge'
}

df_keywords = ['Bitcoin', 'Ethereum', 'Chainlink', 'thorchain', '$Atom', 'Bitforex', '$Avax', 'Terra Luna', '$FTT', 'Safemoon', '$STA', 'Beercoin', 'Teddy Doge']

missing_keywords = set(df_keywords) - set(keyword_to_coin.keys())

if missing_keywords:
    print(f"Missing mappings for keywords: {missing_keywords}")

```
```{python}
df['created'] = pd.to_datetime(df['created'])
df['date'] = df['created'].dt.date
grouped = df.groupby(['search_query', 'date']).size().reset_index(name='count')
grouped = grouped.sort_values('date')
keywords = df['search_query'].unique()
N = len(keywords)


fig, axes = plt.subplots(N, 1, figsize=(12, N * 2), sharex=True)

for i, keyword in enumerate(keywords):
    ax = axes[i] if N > 1 else axes
    data = grouped[grouped['search_query'] == keyword]
    data = data.set_index('date')
    #data = data.reindex(pd.date_range(start=grouped['date'].min(), end=grouped['date'].max(), freq='D'),fill_value = 0)

    
    data['count_smooth'] = data['count']
    ax.plot(data.index, data['count_smooth'])
    ax.set_title(keyword)
    ax.set_ylabel('Count')
    
    coin_name = keyword_to_coin.get(keyword)
    if coin_name:
        start_date, end_date = coin_to_dates.get(coin_name, (None, None))
        if start_date and end_date:
            ax.axvline(x=start_date, color='red', linestyle='--')
            ax.axvline(x=end_date, color='red', linestyle='--')
    
    if i == N - 1:
        ax.set_xlabel('Date')
    else:
        ax.set_xlabel('')
    ax.tick_params(axis='x', rotation=45)
    ax.grid(True)

plt.tight_layout()
plt.suptitle('Count of Search Keywords over Time', y=1.02)
plt.subplots_adjust(hspace=0.3)
plt.show()
```

X

```{python}
#cut out coins of test data
test_coins = ['Ethereum', '$Atom', '$FTT', 'Safemoon']

df_train = df[~df['search_query'].isin(test_coins)]
df_train
```

```{python}
words_list = ['moon', 'mooon', 'to 0', 'to zero', 'scam', 'fraud', 'rug', 'rugpull', 'pump', 'dump', 'rich', 'poor', 'millionaire', 'billionaire']
```

```{python}


# Function to generate heatmaps
def create_heatmaps(df, words_list):
    for keyword in df['search_query'].unique():
        subset = df[df['search_query'] == keyword]
        
        start_date = subset['created'].min().date() - pd.Timedelta(days=10)
        end_date = subset['created'].max().date() + pd.Timedelta(days=10)
        all_dates = pd.date_range(start_date, end_date).date
        
        heatmap_data = pd.DataFrame(0, index=words_list, columns=all_dates)
        
        for _, row in subset.iterrows():
            post_date = row['created'].date()
            for word in words_list:
                if word in row['body'].lower():
                    heatmap_data.at[word, post_date] += 1

        for date in all_dates:
            if date not in heatmap_data.columns:
                heatmap_data[date] = 0
        
        plt.figure(figsize=(12, 6), facecolor='white')
        plt.title(f"Heatmap for search_query: {keyword}", fontsize=14)
        plt.xlabel("Date", fontsize=12)
        plt.ylabel("Words", fontsize=12)

        xticks_indices = np.linspace(0, len(all_dates) - 1, min(10, len(all_dates))).astype(int)
        xticks_labels = [all_dates[i] for i in xticks_indices]
        
        plt.xticks(xticks_indices, xticks_labels, rotation=45, fontsize=10)
        plt.yticks(range(len(words_list)), words_list, fontsize=10)
        
        plt.imshow(heatmap_data, aspect='auto', cmap='viridis', interpolation='nearest', origin='lower')
        plt.colorbar(label='Frequency', orientation='vertical')
        plt.tight_layout()
        plt.show()

create_heatmaps(df_train, words_list)
```

asdf
```{python}

```

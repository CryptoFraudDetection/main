---
title: Crypto Fraud Detection - Data Pipeline Notebook
author: Gabriel Torres Gamez, Florian Baumgartner, Can-Elian Barth, Aaron Br√ºlisauer
execute-dir: file
output-dir: output
toc: true
number-sections: true
number-depth: 2
papersize: a4paper
code-line-numbers: true
code-fold: true
code-overflow: wrap
self-contained: true
jupyter: python3
---

```{python}
#| ExecuteTime: {end_time: '2025-01-04T21:21:59.852373Z', start_time: '2025-01-04T21:21:58.909596Z'}
from pathlib import Path

import pandas as pd

from CryptoFraudDetection.utils import data_pipeline, enums, logger

LOGGER = logger.Logger(
    name=__name__,
    level=enums.LoggerMode.INFO,
    log_dir="../logs",
)
```

```{python}
data_dir = Path("../data")
train_parquet_path = data_dir.joinpath(Path("processed/train.parquet"))
test_parquet_path = data_dir.joinpath(Path("processed/test.parquet"))
if not train_parquet_path.exists() or not test_parquet_path.exists():
    LOGGER.info("Merged data not found, merging data.")
    crypto_data = data_pipeline.CryptoData(data_dir, LOGGER)
    crypto_data.load_data()
    train_df, test_df = crypto_data.preprocess()
    crypto_data.save_data(train_parquet_path, test_parquet_path)
else:
    LOGGER.info("Merged data found, loading merged data.")
    train_df = pd.read_parquet(data_dir.joinpath(train_parquet_path))
    test_df = pd.read_parquet(data_dir.joinpath(test_parquet_path))
```

```{python}
#| ExecuteTime: {start_time: '2025-01-04T21:21:59.858958Z'}
#| jupyter: {is_executing: true}
train_set = data_pipeline.CryptoDataSet(train_df, LOGGER)
test_set = data_pipeline.CryptoDataSet(test_df, LOGGER)
```

```{python}
train_set.__len__(), test_set.__len__()
```

```{python}
train_set.__getitem__(0)
```

